{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrootutils\n",
    "\n",
    "base_path = pyrootutils.setup_root(\n",
    "    search_from=\".\",\n",
    "    indicator=[\".gitignore\"],\n",
    "    project_root_env_var=True,  # set the PROJECT_ROOT environment variable to root directory\n",
    "    dotenv=True,  # load environment variables from .env if exists in root directory\n",
    "    pythonpath=True,  # add root directory to the PYTHONPATH (helps with imports)\n",
    "    cwd=True,  # change current working directory to the root directory (helps with filepaths)\n",
    ")\n",
    "import sys\n",
    "import pickle\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    RichProgressBar,\n",
    "    TQDMProgressBar,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "import wandb\n",
    "import copy\n",
    "import pandas as pd\n",
    "from torch_geometric.nn.resolver import (\n",
    "    activation_resolver,\n",
    "    normalization_resolver,\n",
    ")\n",
    "from omegaconf import DictConfig\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "import hydra\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from hydra.core.utils import _flush_loggers, configure_log\n",
    "\n",
    "from src.data.datasets import *\n",
    "from src.data.datamodules import SpatialDataModule\n",
    "from src.data.graph_utils import check_radius\n",
    "from src.data.utils import load_celltypes, load_sample_names\n",
    "from src.models.modules import DeconvolutionModel, ln_loss, beta_scheduler\n",
    "from src.models.dissect_spatial import DissectSpatial, DissectHetero, DissectSpatialHybrid\n",
    "from src.models.dissect import Dissect\n",
    "from src.utils.utils import seed_everything\n",
    "from src.train import train\n",
    "from src.utils.wandb import *\n",
    "from src.utils.config_utils import *\n",
    "\n",
    "from configs.main_config import config\n",
    "\n",
    "\n",
    "# ignore all warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 80\n",
    "\n",
    "# set seeds\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load configs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load run config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 runs for sweep 4trahk5d\n"
     ]
    }
   ],
   "source": [
    "sweep_ids = [\"4trahk5d\", \"5wtb892z\", \"65rym7bj\"]\n",
    "for sweep_id in sweep_ids[0:1]:\n",
    "    sweep_runs = get_sweep_runs_for_id(sweep_id)\n",
    "    print(f\"Found {len(sweep_runs)} runs for sweep {sweep_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity=\"dschaub\"\n",
    "project=\"DISSECT-src\"\n",
    "# project = \"dissect-spatial\"\n",
    "api = wandb.Api()\n",
    "runs = api.runs(entity + \"/\" + project, filters={\"sweep\": sweep_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dev']\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(run.config[\"tags\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_names = []\n",
    "mean_cccs = []\n",
    "mena_rmses = []\n",
    "t = 1\n",
    "for run in runs:\n",
    "    # mean_ccc = run.history(keys=[\"validation/mean_ccc\"])[\"validation/mean_ccc\"].iloc[-1]\n",
    "    try:\n",
    "        mean_ccc = run.history(keys=[\"validation/mean_ccc\"])[\"validation/mean_ccc\"].iloc[-1]\n",
    "        mean_rmse = run.history(keys=[\"validation/mean_rmse\"])[\"validation/mean_rmse\"].iloc[-1]\n",
    "    except:\n",
    "        continue\n",
    "    if isinstance(mean_ccc, str):\n",
    "        continue\n",
    "    mean_cccs.append(mean_ccc)\n",
    "    mena_rmses.append(mean_rmse)\n",
    "    run_names.append(run.name)\n",
    "    t += 1\n",
    "    if t > 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top k runs\n",
    "k = 5\n",
    "top_k_indices = np.argsort(mean_cccs)[-k:]\n",
    "top_k_runs = [run_names[i] for i in top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_name in top_k_runs:\n",
    "    run_config = get_run_config(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = get_run_config(run_name=\"sweet-sweep-72\", project=\"DISSECT-src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: hybrid\n"
     ]
    }
   ],
   "source": [
    "if \"experiment\" in run_config:\n",
    "    experiment_name = run_config[\"experiment\"]\n",
    "    del run_config[\"experiment\"]\n",
    "else:\n",
    "    experiment_name = None\n",
    "print(f\"Experiment name: {experiment_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load base config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "# import GlobalHydra\n",
    "\n",
    "config_path = \"../configs\"\n",
    "config_name = \"train.yaml\"\n",
    "\n",
    "initialize(version_base=\"1.3\", config_path=config_path)\n",
    "if experiment_name is not None:\n",
    "    overrides = [f\"experiment={experiment_name}\"]\n",
    "else:\n",
    "    overrides = []\n",
    "config = compose(\n",
    "    config_name=config_name,\n",
    "    overrides=overrides,\n",
    "    return_hydra_config=True,\n",
    ")\n",
    "HydraConfig.instance().set_config(config)\n",
    "OmegaConf.set_struct(config, False)\n",
    "del config[\"hydra\"]\n",
    "# print_config(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net in config: False\n"
     ]
    }
   ],
   "source": [
    "config = prepare_config(config, run_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdschaub\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/DISSECT/logs/wandb/run-20230403_195826-bd5u0b2a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dschaub/dissect-spatial/runs/bd5u0b2a' target=\"_blank\">lyric-shape-187</a></strong> to <a href='https://wandb.ai/dschaub/dissect-spatial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dschaub/dissect-spatial' target=\"_blank\">https://wandb.ai/dschaub/dissect-spatial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dschaub/dissect-spatial/runs/bd5u0b2a' target=\"_blank\">https://wandb.ai/dschaub/dissect-spatial/runs/bd5u0b2a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                 </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ net  │ DissectSpatialHybrid │  3.1 M │\n",
       "└───┴──────┴──────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ net  │ DissectSpatialHybrid │  3.1 M │\n",
       "└───┴──────┴──────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 3.1 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 3.1 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 12                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 3.1 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 3.1 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 12                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": [
       "\u001b[?25l"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cda483030f4b73b2daada6751526fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config.extras.print_config = False\n",
    "config.model.save_predictions = True\n",
    "config.model.plotting = False\n",
    "config.trainer.devices = [7]\n",
    "wandb_mode = \"online\"\n",
    "config.logger.wandb.mode = wandb_mode\n",
    "# config.logger.wandb.name = \"test123\"\n",
    "train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissect_spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
