{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "base_path = \"..\"\n",
    "sys.path.append(base_path)\n",
    "\n",
    "import pickle\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.data import Dataset, Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import torch_geometric as pyg\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    RichProgressBar,\n",
    "    TQDMProgressBar,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from utils.gnn_utils import *\n",
    "from utils.gnn import *\n",
    "from utils.module import *\n",
    "from utils.utils import seed_everything\n",
    "from src.data.datasets import *\n",
    "\n",
    "from configs.main_config import config\n",
    "\n",
    "\n",
    "# ignore all warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 80\n",
    "\n",
    "# set seeds\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{base_path}/data\"\n",
    "\n",
    "experiment_dir = \"experiments/experiment_bulk_real\"\n",
    "\n",
    "bulk_data_dir = f\"{data_dir}/bulk\"\n",
    "bulk_data = sc.read_text(f\"{bulk_data_dir}/GSE120502.txt\").T\n",
    "\n",
    "# load previously prepared data\n",
    "X_real, X_real_train, X_sim, y_sim = load_prepared_data(f\"{experiment_dir}/datasets\")\n",
    "\n",
    "# load cell types\n",
    "celltype_names = load_celltypes(f\"{experiment_dir}/datasets/celltypes.txt\")\n",
    "\n",
    "# load real groundtruth if available\n",
    "y_real, y_real_df = load_real_groundtruth(\n",
    "    f\"{bulk_data_dir}/gt_GSE120502.txt\", col_order=celltype_names\n",
    ")\n",
    "\n",
    "sim_data_dir = f\"{data_dir}/simulated\"\n",
    "sim_data = sc.read_h5ad(f\"{sim_data_dir}/simulated_pbmc8k_qc.h5ad\")\n",
    "\n",
    "st_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cell types\n",
    "celltype_names = load_celltypes(f\"{experiment_dir}/datasets/celltypes.txt\")\n",
    "\n",
    "# load sample names\n",
    "sample_names = load_sample_names(f\"{experiment_dir}/datasets/sample_names.txt\")\n",
    "\n",
    "# load previously prepared data\n",
    "X_real, X_real_train, X_sim, y_sim = load_prepared_data(f\"{experiment_dir}/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prepare_dataset(X_real_train, X_sim, y_sim, y_real=y_real, st_data=st_data)\n",
    "test_data = prepare_dataset(X_real, X_sim, y_sim, y_real=y_real, st_data=st_data)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data, batch_size=3000, shuffle=False, pin_memory=True, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Dissect(\n",
    "    num_genes=X_real.shape[1],\n",
    "    num_celltypes=y_sim.shape[1],\n",
    ")\n",
    "\n",
    "model = DeconvolutionModel(\n",
    "    net,\n",
    "    # l1_lambda=0.0,\n",
    "    # l2_lambda=0.0,\n",
    "    sim_loss_fn=\"kl_div\",\n",
    "    spatial_data=st_data,\n",
    "    celltype_names=celltype_names,\n",
    "    sample_names=sample_names,\n",
    ")\n",
    "\n",
    "# setup callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"train/total_loss\", mode=\"min\", save_last=True, dirpath=\"checkpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "wandb_mode = \"online\"\n",
    "# wandb_mode = \"disabled\"\n",
    "wandb_logger = WandbLogger(project=\"dissect-spatial\", log_model=True, mode=wandb_mode)\n",
    "\n",
    "# training\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5000,\n",
    "    max_steps=-1,\n",
    "    accelerator=\"gpu\",\n",
    "    limit_train_batches=1,\n",
    "    log_every_n_steps=1,\n",
    "    check_val_every_n_epoch=500,\n",
    "    devices=[7],\n",
    "    precision=32,\n",
    "    logger=wandb_logger,\n",
    "    deterministic=\"warn\",\n",
    "    enable_checkpointing=True,\n",
    "    # fast_dev_run=True,\n",
    "    # profiler=\"simple\",\n",
    "    enable_progress_bar=False,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "val_dataloaders = test_loader\n",
    "# val_dataloaders = None\n",
    "trainer.fit(model, train_loader, val_dataloaders=val_dataloaders)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissect_spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f49dfde4eb06c0a3671c2401bd6b6f73cacae937d3de5334273372658b299ab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
